{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f5417961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          filename  meanFWHM_1  meanFWHM_2  \\\n",
      "0   ZT10_16X6x_gg_800nm_m10_roi1_00001_ROIs_classA    3.977697    2.942062   \n",
      "1   ZT10_16X6x_gg_800nm_m10_roi3_00002_ROIs_classA         NaN    4.631581   \n",
      "2   ZT10_16X6x_gg_800nm_m11_roi1_00001_ROIs_classA    6.396367    4.987402   \n",
      "3   ZT10_16X6x_gg_800nm_m11_roi2_00001_ROIs_classA         NaN    4.033243   \n",
      "4   ZT10_16X6x_gg_800nm_m11_roi3_00001_ROIs_classA    4.509682    4.723290   \n",
      "5   ZT10_16X6x_gg_800nm_m12_roi1_00001_ROIs_classA   13.111133    6.520617   \n",
      "6   ZT10_16X6x_gg_800nm_m12_roi2_00001_ROIs_classA         NaN    5.450242   \n",
      "7   ZT10_16X6x_gg_800nm_m12_roi3_00001_ROIs_classA    4.657313    3.726194   \n",
      "8   ZT10_16X6x_gg_800nm_m13_roi1_00002_ROIs_classA    7.531767    5.655471   \n",
      "9   ZT10_16X6x_gg_800nm_m13_roi2_00001_ROIs_classA         NaN    6.329994   \n",
      "10  ZT10_16X6x_gg_800nm_m13_roi3_00001_ROIs_classA    4.253996    4.652714   \n",
      "11  ZT10_16X6x_gg_800nm_m15_roi1_00001_ROIs_classA    7.039957    4.562134   \n",
      "12  ZT10_16X6x_gg_800nm_m15_roi2_00001_ROIs_classA    3.768027    4.352967   \n",
      "13  ZT10_16X6x_gg_800nm_m16_roi1_00001_ROIs_classA    3.995751    6.654573   \n",
      "14  ZT10_16X6x_gg_800nm_m16_roi2_00001_ROIs_classA         NaN    3.411384   \n",
      "15   ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA    3.740378    4.100067   \n",
      "16   ZT10_16X6x_gg_800nm_m5_roi3_00001_ROIs_classA         NaN         NaN   \n",
      "17   ZT10_16X6x_gg_800nm_m6_roi1_00001_ROIs_classA    5.886713    4.679207   \n",
      "18   ZT10_16X6x_gg_800nm_m6_roi2_00001_ROIs_classA         NaN         NaN   \n",
      "19   ZT10_16X6x_gg_800nm_m6_roi3_00001_ROIs_classA    4.443435    3.919023   \n",
      "20   ZT10_16X6x_gg_800nm_m7_roi1_00001_ROIs_classA    4.079630    3.446943   \n",
      "21   ZT10_16X6x_gg_800nm_m9_roi1_00002_ROIs_classA    4.979717    4.802855   \n",
      "22   ZT10_16X6x_gg_800nm_m9_roi3_00001_ROIs_classA    3.136460    2.940673   \n",
      "\n",
      "    meanFWHM_3  meanFWHM_4  meanFWHM_5  meanFWHM_6  meanFWHM_7  meanFWHM_8  \\\n",
      "0     5.012042    5.936727    5.160015    4.400999    3.628295    5.456183   \n",
      "1     7.699324    2.935723    2.655824    4.356524    4.293618    5.655721   \n",
      "2     4.438525    6.238129    3.652761         NaN         NaN         NaN   \n",
      "3     5.360953    3.303419    2.616768    4.965854    4.489936    3.214756   \n",
      "4     5.187616    4.964916    5.129645    4.485358   10.723340    5.778633   \n",
      "5    17.666502    6.903404    7.024061    5.315032    3.697160    5.283661   \n",
      "6    12.343775    5.211834    5.278937    4.480280    5.025853    3.615951   \n",
      "7     4.196140    5.014225    7.291781    4.775703    6.660684    5.287168   \n",
      "8     5.116886    5.537170    5.394427    6.738384    3.725344    5.257257   \n",
      "9     3.687090    4.037768    3.858535    4.338482    3.743455    3.528348   \n",
      "10    3.198735    3.491843    4.544638    4.546004         NaN    3.656095   \n",
      "11    3.755965    5.039959    5.512683    4.090433    4.706815    6.252597   \n",
      "12    4.242189    3.267641    5.241061         NaN    4.858550         NaN   \n",
      "13    2.871763    8.258790    5.911228    5.490259    4.254866    5.549062   \n",
      "14    4.005835    6.787617    5.816519    4.390754    4.813701    4.484175   \n",
      "15    6.326261    6.066305         NaN         NaN         NaN         NaN   \n",
      "16         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "17    6.691621    6.233091    5.106044         NaN         NaN         NaN   \n",
      "18         NaN         NaN         NaN         NaN         NaN         NaN   \n",
      "19    5.440260    5.657550    4.325984    4.132347    4.076147         NaN   \n",
      "20    4.057460         NaN    5.208817         NaN         NaN         NaN   \n",
      "21    3.776378    3.367183    6.708486    4.419400    4.370948    7.461568   \n",
      "22    4.854804         NaN    2.905915    3.131670    2.909657    3.562394   \n",
      "\n",
      "    meanFWHM_9  ...  pstArtLogical_11  pstArtLogical_12  pstArtLogical_13  \\\n",
      "0     6.649782  ...               0.0               NaN               NaN   \n",
      "1     5.950348  ...               0.0               NaN               NaN   \n",
      "2          NaN  ...               NaN               NaN               NaN   \n",
      "3     7.504347  ...               0.0               0.0               0.0   \n",
      "4     3.567816  ...               NaN               NaN               NaN   \n",
      "5     5.636838  ...               0.0               0.0               0.0   \n",
      "6     5.114944  ...               NaN               NaN               NaN   \n",
      "7     7.528695  ...               NaN               NaN               NaN   \n",
      "8     4.485320  ...               0.0               0.0               NaN   \n",
      "9     3.037721  ...               0.0               0.0               0.0   \n",
      "10    6.550423  ...               0.0               0.0               0.0   \n",
      "11         NaN  ...               NaN               NaN               NaN   \n",
      "12         NaN  ...               NaN               NaN               NaN   \n",
      "13         NaN  ...               NaN               NaN               NaN   \n",
      "14    4.959572  ...               NaN               NaN               NaN   \n",
      "15         NaN  ...               NaN               NaN               NaN   \n",
      "16         NaN  ...               NaN               NaN               NaN   \n",
      "17         NaN  ...               NaN               NaN               NaN   \n",
      "18         NaN  ...               NaN               NaN               NaN   \n",
      "19         NaN  ...               NaN               NaN               NaN   \n",
      "20         NaN  ...               NaN               NaN               NaN   \n",
      "21         NaN  ...               NaN               NaN               NaN   \n",
      "22    5.081917  ...               0.0               0.0               0.0   \n",
      "\n",
      "    pstArtLogical_14  pstArtLogical_15  pstArtLogical_16  pstArtLogical_17  \\\n",
      "0                NaN               NaN               NaN               NaN   \n",
      "1                NaN               NaN               NaN               NaN   \n",
      "2                NaN               NaN               NaN               NaN   \n",
      "3                0.0               0.0               0.0               NaN   \n",
      "4                NaN               NaN               NaN               NaN   \n",
      "5                0.0               0.0               0.0               0.0   \n",
      "6                NaN               NaN               NaN               NaN   \n",
      "7                NaN               NaN               NaN               NaN   \n",
      "8                NaN               NaN               NaN               NaN   \n",
      "9                0.0               0.0               NaN               NaN   \n",
      "10               NaN               NaN               NaN               NaN   \n",
      "11               NaN               NaN               NaN               NaN   \n",
      "12               NaN               NaN               NaN               NaN   \n",
      "13               NaN               NaN               NaN               NaN   \n",
      "14               NaN               NaN               NaN               NaN   \n",
      "15               NaN               NaN               NaN               NaN   \n",
      "16               NaN               NaN               NaN               NaN   \n",
      "17               NaN               NaN               NaN               NaN   \n",
      "18               NaN               NaN               NaN               NaN   \n",
      "19               NaN               NaN               NaN               NaN   \n",
      "20               NaN               NaN               NaN               NaN   \n",
      "21               NaN               NaN               NaN               NaN   \n",
      "22               0.0               NaN               NaN               NaN   \n",
      "\n",
      "    pstArtLogical_18  pstArtLogical_19  group  \n",
      "0                NaN               NaN      A  \n",
      "1                NaN               NaN      A  \n",
      "2                NaN               NaN      A  \n",
      "3                NaN               NaN      A  \n",
      "4                NaN               NaN      A  \n",
      "5                0.0               0.0      A  \n",
      "6                NaN               NaN      A  \n",
      "7                NaN               NaN      A  \n",
      "8                NaN               NaN      B  \n",
      "9                NaN               NaN      B  \n",
      "10               NaN               NaN      B  \n",
      "11               NaN               NaN      B  \n",
      "12               NaN               NaN      B  \n",
      "13               NaN               NaN      B  \n",
      "14               NaN               NaN      B  \n",
      "15               NaN               NaN      A  \n",
      "16               NaN               NaN      A  \n",
      "17               NaN               NaN      A  \n",
      "18               NaN               NaN      A  \n",
      "19               NaN               NaN      A  \n",
      "20               NaN               NaN      B  \n",
      "21               NaN               NaN      A  \n",
      "22               NaN               NaN      A  \n",
      "\n",
      "[23 rows x 498 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "pathname = '/Users/jcoleman/Documents/--LARGE DATA--/#Pizzi/TBI-sham leak analysis/scripts/matlab-copy/August 2024/'\n",
    "filename = 'analysisData.csv'\n",
    "df = pd.read_csv(pathname+filename)\n",
    "\n",
    "print(df)\n",
    "# Basic analysis: means, std, etc.\n",
    "#group_means = df.groupby('group')['meanFWHM'].mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b1960fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.745207\n",
      "1     0.613909\n",
      "2     2.186275\n",
      "3     0.793577\n",
      "4     0.899971\n",
      "5     0.970099\n",
      "6     0.596895\n",
      "7     1.262551\n",
      "8     0.772685\n",
      "9     0.771129\n",
      "10    0.504174\n",
      "11    1.127653\n",
      "12    1.759821\n",
      "13    0.567743\n",
      "14    0.616087\n",
      "15    0.488151\n",
      "16         NaN\n",
      "17    0.960499\n",
      "18         NaN\n",
      "19    0.721188\n",
      "20    1.155816\n",
      "21    0.689951\n",
      "22    0.773838\n",
      "Name: row_meanFeFv, dtype: float64\n",
      "Means: group\n",
      "A    0.900163\n",
      "B    0.909388\n",
      "Name: row_meanFeFv, dtype: float64 Stdev: group\n",
      "A    0.434469\n",
      "B    0.420264\n",
      "Name: row_meanFeFv, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Sample dataframe structure for illustration\n",
    "# df = pd.read_csv('analysisData.csv')\n",
    "\n",
    "# Step 1: Identify columns that contain ' '\n",
    "meanFeFv_cols = [col for col in df.columns if 'meanFeFv_' in col]\n",
    "\n",
    "# Step 2: Compute the row-wise mean for these columns\n",
    "df['row_meanFeFv'] = df[meanFeFv_cols].mean(axis=1)\n",
    "\n",
    "#print(df['row_meanFWHM'])\n",
    "print(df['row_meanFeFv'])\n",
    "\n",
    "# Step 3: Now, you can compute the group-wise mean based on 'group'\n",
    "group_means = df.groupby('group')['row_meanFeFv'].mean()\n",
    "group_stdev = df.groupby('group')['row_meanFeFv'].std()\n",
    "\n",
    "# Optional: View the result\n",
    "print(\"Means:\", group_means, \"Stdev:\", group_stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e845c724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.cluster import KMeans\n",
    "# # import umap\n",
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# # Sample dataframe structure for illustration\n",
    "# # df = pd.read_csv('analysisData.csv')\n",
    "\n",
    "# # Step 1: Dynamically identify columns that contain the relevant substrings and filter with logicals\n",
    "\n",
    "# # Pre-bif cap, Pre-bif venule, Pre-bif arteriole\n",
    "# # Mid-cap, Mid-venule, Mid-arteriole\n",
    "# # Post-bif cap, Post-bif venule, Post-bif arteriole\n",
    "# #categorical_strings = ['Mid-cap', 'Pre-bif cap', 'Post-bif cap', 'Mid-venule', 'Pre-bif venule', 'Post-bif venule']\n",
    "# logicalType_cols = ['cap', 'ven', 'art']\n",
    "# logicalPos_cols = ['midCap', 'preCap', 'pstCap', 'midVen', 'preVen', 'pstVen','midArt', 'preArt', 'pstArt']\n",
    "# vesselType_cols = [col for col in df.columns if any(string in col for string in logicalType_cols)]\n",
    "# # print(categorical_strings)\n",
    "# # print(categorical_cols)\n",
    "# # print(df['roiName'][0])\n",
    "# print(logicalType_cols)\n",
    "# print(logicalPos_cols)\n",
    "# print(vesselType_cols)\n",
    "\n",
    "# # get all columns\n",
    "# mean_cols = [col for col in df.columns if 'meanFeFv' in col]\n",
    "# stdev_cols = [col for col in df.columns if 'stdevFeFv' in col]\n",
    "# min_cols = [col for col in df.columns if 'minFeFv' in col]\n",
    "# max_cols = [col for col in df.columns if 'maxFeFv' in col]\n",
    "\n",
    "# # get columns using logicals ie columns filtered using logicals above\n",
    "# # mean_cols_art = [col for col in mean_cols if (df['artLogical_' + col.split('_')[1]] == 1).any()]\n",
    "# mean_cols_cap = [col for col in mean_cols if f\"capLogical_{col[-2:]}\" in df.columns and (df[f\"capLogical_{col[-2:]}\"] == 1).any()]\n",
    "\n",
    "# ##mean_cols_cap = [col for col in mean_cols if (df['capLogical_' + col.split('_')[1]] == 1).any()]\n",
    "# mean_cols_ven = [col for col in mean_cols if df['venLogical_' + col.split('_')[1]] == 1]\n",
    "# mean_cols_art = [col for col in mean_cols if df['artLogical_' + col.split('_')[1]] == 1]\n",
    "# stdev_cols_cap = [col for col in stdev_cols if df['capLogical_' + col.split('_')[1]] == 1]\n",
    "# stdev_cols_ven = [col for col in stdev_cols if df['venLogical_' + col.split('_')[1]] == 1]\n",
    "# stdev_cols_art = [col for col in stdev_cols if df['artLogical_' + col.split('_')[1]] == 1]\n",
    "# min_cols_cap = [col for col in min_cols if df['capLogical_' + col.split('_')[1]] == 1]\n",
    "# min_cols_ven = [col for col in min_cols if df['venLogical_' + col.split('_')[1]] == 1]\n",
    "# min_cols_art = [col for col in min_cols if df['artLogical_' + col.split('_')[1]] == 1]\n",
    "# max_cols_cap = [col for col in max_cols if df['capLogical_' + col.split('_')[1]] == 1]\n",
    "# max_cols_ven = [col for col in max_cols if df['venLogical_' + col.split('_')[1]] == 1]\n",
    "# max_cols_art = [col for col in max_cols if df['artLogical_' + col.split('_')[1]] == 1]\n",
    "\n",
    "# # # Get the list of unique 'roiName' strings\n",
    "# # roi_names = df[logicalType_cols[0]].unique()\n",
    "# # print(roi_names[0])\n",
    "\n",
    "# # Combine all relevant columns\n",
    "# relevant_columns = mean_cols_cap + mean_cols_ven + mean_cols_art +stdev_cols_cap + stdev_cols_ven + stdev_cols_art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b5f082dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "\n",
    "# WORKS 9-11-24 try1\n",
    "\n",
    "# Example DataFrame creation with multiple rows\n",
    "data = {\n",
    "    'filename': ['ZT10_16X6x_gg_800nm_m10_roi1_00001_ROIs_classA',\n",
    "                 'ZT10_16X6x_gg_800nm_m10_roi2_00001_ROIs_classB',\n",
    "                 'ZT10_16X6x_gg_800nm_m10_roi3_00001_ROIs_classC'],\n",
    "    'capLogical_1': [1, 0, 1],\n",
    "    'capLogical_2': [0, 1, 0],\n",
    "    'capLogical_3': [0, 0, 1],\n",
    "    'venLogical_1': [0, 1, 0],\n",
    "    'venLogical_2': [1, 0, 1],\n",
    "    'venLogical_3': [0, 0, 0],\n",
    "    'artLogical_1': [0, 1, 1],\n",
    "    'artLogical_2': [0, 0, 0],\n",
    "    'artLogical_3': [1, 1, 1],  # Corrected to make sure there's variability\n",
    "    'meanFeFv_1': [0.338031439, 0.4, 0.5],\n",
    "    'meanFeFv_2': [0.697814648, 0.6, 0.7],\n",
    "    'meanFeFv_3': [0.6, 0.7, 0.8],\n",
    "    'meanFeFv_4': [None, 0.8, None],  # Example additional means\n",
    "    'meanFeFv_5': [None, None, 1.0],\n",
    "}\n",
    "\n",
    "#df_copy=df\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# Define logical and mean column prefixes\n",
    "# logicalType_cols = ['cap', 'ven', 'art']\n",
    "# mean_col_prefix = 'meanFeFv_'\n",
    "logical_col_prefixes = ['capLogical_', 'venLogical_', 'artLogical_']\n",
    "\n",
    "# Get mean columns, etc\n",
    "mean_cols = [col for col in df.columns if 'meanFeFv' in col]\n",
    "x_cols = [col for col in df.columns if 'X' in col]\n",
    "y_cols = [col for col in df.columns if 'Y' in col]\n",
    "z_cols = [col for col in df.columns if 'Z' in col]\n",
    "\n",
    "# Create a dictionary to hold the filtered columns for each logical type\n",
    "filtered_cols = {}\n",
    "\n",
    "# Function to get filtered columns based on logical values for each row\n",
    "def get_filtered_cols(row, logical_prefix, mean_prefix, logical_cols):\n",
    "    filtered_mean_cols = []\n",
    "    for i, logical_col in enumerate(logical_cols):\n",
    "        if row[logical_col] == 1:\n",
    "            mean_col = f\"{mean_prefix}{i+1}\"\n",
    "            if mean_col in mean_cols:\n",
    "                filtered_mean_cols.append(mean_col)\n",
    "    return filtered_mean_cols\n",
    "\n",
    "# Process each row\n",
    "for index, row in df.iterrows():\n",
    "    # Filter for each vessel type (cap, ven, art) based on row\n",
    "    row_filtered_cols = {}\n",
    "    for logical_prefix in logical_col_prefixes:\n",
    "        vessel_type = logical_prefix.rstrip('Logical_')  # Extract vessel type from prefix\n",
    "        logical_cols = [col for col in df.columns if col.startswith(logical_prefix)]\n",
    "        row_filtered_cols[vessel_type] = get_filtered_cols(row, vessel_type, 'meanFeFv_', logical_cols)\n",
    "    \n",
    "    filename = row['filename']\n",
    "    filtered_cols[filename] = row_filtered_cols\n",
    "\n",
    "# # Print the filtered columns for each row\n",
    "# for filename, cols in filtered_cols.items():\n",
    "#     print(f\"Filtered columns for file '{filename}':\")\n",
    "#     for vessel_type, columns in cols.items():\n",
    "#         print(f\"  {vessel_type}: {columns}\")\n",
    "        \n",
    "# Exampke output...\n",
    "# Filtered columns for file 'ZT10_16X6x_gg_800nm_m10_roi1_00001_ROIs_classA':\n",
    "#   cap: ['meanFeFv_1', 'meanFeFv_2', 'meanFeFv_3', 'meanFeFv_4', 'meanFeFv_5', 'meanFeFv_6', 'meanFeFv_7', 'meanFeFv_8']\n",
    "#   ven: ['meanFeFv_9', 'meanFeFv_10']\n",
    "#   art: []\n",
    "# Filtered columns for file 'ZT10_16X6x_gg_800nm_m10_roi3_00002_ROIs_classA':\n",
    "#   cap: ['meanFeFv_2', 'meanFeFv_3', 'meanFeFv_4', 'meanFeFv_5', 'meanFeFv_6', 'meanFeFv_7', 'meanFeFv_8', 'meanFeFv_9', 'meanFeFv_10', 'meanFeFv_11']\n",
    "#   ven: []\n",
    "#   art: []..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "24f7b47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m10_roi1_00001_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m10_roi3_00002_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m11_roi1_00001_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m11_roi2_00001_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m11_roi3_00001_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m12_roi1_00001_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m12_roi2_00001_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m12_roi3_00001_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m13_roi1_00002_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m13_roi2_00001_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m13_roi3_00001_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m15_roi1_00001_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m15_roi2_00001_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m16_roi1_00001_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m16_roi2_00001_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m5_roi3_00001_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m6_roi1_00001_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m6_roi2_00001_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m6_roi3_00001_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m7_roi1_00001_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m9_roi1_00002_ROIs_classA':\n",
      "cap\n",
      "Filtered 'cap' columns for file 'ZT10_16X6x_gg_800nm_m9_roi3_00001_ROIs_classA':\n",
      "cap\n",
      "{'ZT10_16X6x_gg_800nm_m10_roi1_00001_ROIs_classA': {'mean': ['meanFeFv_1', 'meanFeFv_2', 'meanFeFv_3', 'meanFeFv_4', 'meanFeFv_5', 'meanFeFv_6', 'meanFeFv_7', 'meanFeFv_8'], 'X': ['X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7', 'X_8'], 'Y': ['Y_1', 'Y_2', 'Y_3', 'Y_4', 'Y_5', 'Y_6', 'Y_7', 'Y_8'], 'Z': ['Z_1', 'Z_2', 'Z_3', 'Z_4', 'Z_5', 'Z_6', 'Z_7', 'Z_8']}, 'ZT10_16X6x_gg_800nm_m10_roi3_00002_ROIs_classA': {'mean': ['meanFeFv_2', 'meanFeFv_3', 'meanFeFv_4', 'meanFeFv_5', 'meanFeFv_6', 'meanFeFv_7', 'meanFeFv_8', 'meanFeFv_9', 'meanFeFv_10', 'meanFeFv_11'], 'X': ['X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7', 'X_8', 'X_9', 'X_10', 'X_11'], 'Y': ['Y_2', 'Y_3', 'Y_4', 'Y_5', 'Y_6', 'Y_7', 'Y_8', 'Y_9', 'Y_10', 'Y_11'], 'Z': ['Z_2', 'Z_3', 'Z_4', 'Z_5', 'Z_6', 'Z_7', 'Z_8', 'Z_9', 'Z_10', 'Z_11']}, 'ZT10_16X6x_gg_800nm_m11_roi1_00001_ROIs_classA': {'mean': ['meanFeFv_1', 'meanFeFv_2', 'meanFeFv_3', 'meanFeFv_4', 'meanFeFv_5'], 'X': ['X_1', 'X_2', 'X_3', 'X_4', 'X_5'], 'Y': ['Y_1', 'Y_2', 'Y_3', 'Y_4', 'Y_5'], 'Z': ['Z_1', 'Z_2', 'Z_3', 'Z_4', 'Z_5']}, 'ZT10_16X6x_gg_800nm_m11_roi2_00001_ROIs_classA': {'mean': ['meanFeFv_2', 'meanFeFv_3', 'meanFeFv_4', 'meanFeFv_5', 'meanFeFv_6', 'meanFeFv_7', 'meanFeFv_8', 'meanFeFv_9', 'meanFeFv_10', 'meanFeFv_11', 'meanFeFv_12', 'meanFeFv_13', 'meanFeFv_14', 'meanFeFv_15', 'meanFeFv_16'], 'X': ['X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7', 'X_8', 'X_9', 'X_10', 'X_11', 'X_12', 'X_13', 'X_14', 'X_15', 'X_16'], 'Y': ['Y_2', 'Y_3', 'Y_4', 'Y_5', 'Y_6', 'Y_7', 'Y_8', 'Y_9', 'Y_10', 'Y_11', 'Y_12', 'Y_13', 'Y_14', 'Y_15', 'Y_16'], 'Z': ['Z_2', 'Z_3', 'Z_4', 'Z_5', 'Z_6', 'Z_7', 'Z_8', 'Z_9', 'Z_10', 'Z_11', 'Z_12', 'Z_13', 'Z_14', 'Z_15', 'Z_16']}, 'ZT10_16X6x_gg_800nm_m11_roi3_00001_ROIs_classA': {'mean': ['meanFeFv_1', 'meanFeFv_2', 'meanFeFv_3', 'meanFeFv_4', 'meanFeFv_5', 'meanFeFv_6', 'meanFeFv_9'], 'X': ['X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_9'], 'Y': ['Y_1', 'Y_2', 'Y_3', 'Y_4', 'Y_5', 'Y_6', 'Y_9'], 'Z': ['Z_1', 'Z_2', 'Z_3', 'Z_4', 'Z_5', 'Z_6', 'Z_9']}, 'ZT10_16X6x_gg_800nm_m12_roi1_00001_ROIs_classA': {'mean': ['meanFeFv_6', 'meanFeFv_7', 'meanFeFv_8', 'meanFeFv_9', 'meanFeFv_10', 'meanFeFv_11', 'meanFeFv_12', 'meanFeFv_13', 'meanFeFv_14', 'meanFeFv_15', 'meanFeFv_16', 'meanFeFv_17'], 'X': ['X_6', 'X_7', 'X_8', 'X_9', 'X_10', 'X_11', 'X_12', 'X_13', 'X_14', 'X_15', 'X_16', 'X_17'], 'Y': ['Y_6', 'Y_7', 'Y_8', 'Y_9', 'Y_10', 'Y_11', 'Y_12', 'Y_13', 'Y_14', 'Y_15', 'Y_16', 'Y_17'], 'Z': ['Z_6', 'Z_7', 'Z_8', 'Z_9', 'Z_10', 'Z_11', 'Z_12', 'Z_13', 'Z_14', 'Z_15', 'Z_16', 'Z_17']}, 'ZT10_16X6x_gg_800nm_m12_roi2_00001_ROIs_classA': {'mean': ['meanFeFv_2', 'meanFeFv_4', 'meanFeFv_5', 'meanFeFv_6', 'meanFeFv_7', 'meanFeFv_8', 'meanFeFv_9'], 'X': ['X_2', 'X_4', 'X_5', 'X_6', 'X_7', 'X_8', 'X_9'], 'Y': ['Y_2', 'Y_4', 'Y_5', 'Y_6', 'Y_7', 'Y_8', 'Y_9'], 'Z': ['Z_2', 'Z_4', 'Z_5', 'Z_6', 'Z_7', 'Z_8', 'Z_9']}, 'ZT10_16X6x_gg_800nm_m12_roi3_00001_ROIs_classA': {'mean': ['meanFeFv_1', 'meanFeFv_2', 'meanFeFv_3', 'meanFeFv_4', 'meanFeFv_6', 'meanFeFv_8'], 'X': ['X_1', 'X_2', 'X_3', 'X_4', 'X_6', 'X_8'], 'Y': ['Y_1', 'Y_2', 'Y_3', 'Y_4', 'Y_6', 'Y_8'], 'Z': ['Z_1', 'Z_2', 'Z_3', 'Z_4', 'Z_6', 'Z_8']}, 'ZT10_16X6x_gg_800nm_m13_roi1_00002_ROIs_classA': {'mean': ['meanFeFv_2', 'meanFeFv_3', 'meanFeFv_4', 'meanFeFv_5', 'meanFeFv_6', 'meanFeFv_7', 'meanFeFv_8', 'meanFeFv_9', 'meanFeFv_10', 'meanFeFv_11'], 'X': ['X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7', 'X_8', 'X_9', 'X_10', 'X_11'], 'Y': ['Y_2', 'Y_3', 'Y_4', 'Y_5', 'Y_6', 'Y_7', 'Y_8', 'Y_9', 'Y_10', 'Y_11'], 'Z': ['Z_2', 'Z_3', 'Z_4', 'Z_5', 'Z_6', 'Z_7', 'Z_8', 'Z_9', 'Z_10', 'Z_11']}, 'ZT10_16X6x_gg_800nm_m13_roi2_00001_ROIs_classA': {'mean': ['meanFeFv_2', 'meanFeFv_3', 'meanFeFv_4', 'meanFeFv_5', 'meanFeFv_6', 'meanFeFv_7', 'meanFeFv_8', 'meanFeFv_9', 'meanFeFv_10', 'meanFeFv_11', 'meanFeFv_12', 'meanFeFv_13', 'meanFeFv_14'], 'X': ['X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7', 'X_8', 'X_9', 'X_10', 'X_11', 'X_12', 'X_13', 'X_14'], 'Y': ['Y_2', 'Y_3', 'Y_4', 'Y_5', 'Y_6', 'Y_7', 'Y_8', 'Y_9', 'Y_10', 'Y_11', 'Y_12', 'Y_13', 'Y_14'], 'Z': ['Z_2', 'Z_3', 'Z_4', 'Z_5', 'Z_6', 'Z_7', 'Z_8', 'Z_9', 'Z_10', 'Z_11', 'Z_12', 'Z_13', 'Z_14']}, 'ZT10_16X6x_gg_800nm_m13_roi3_00001_ROIs_classA': {'mean': ['meanFeFv_1', 'meanFeFv_2', 'meanFeFv_3', 'meanFeFv_4', 'meanFeFv_5', 'meanFeFv_6', 'meanFeFv_7', 'meanFeFv_8'], 'X': ['X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7', 'X_8'], 'Y': ['Y_1', 'Y_2', 'Y_3', 'Y_4', 'Y_5', 'Y_6', 'Y_7', 'Y_8'], 'Z': ['Z_1', 'Z_2', 'Z_3', 'Z_4', 'Z_5', 'Z_6', 'Z_7', 'Z_8']}, 'ZT10_16X6x_gg_800nm_m15_roi1_00001_ROIs_classA': {'mean': ['meanFeFv_1', 'meanFeFv_2', 'meanFeFv_3', 'meanFeFv_4', 'meanFeFv_5', 'meanFeFv_6', 'meanFeFv_7'], 'X': ['X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7'], 'Y': ['Y_1', 'Y_2', 'Y_3', 'Y_4', 'Y_5', 'Y_6', 'Y_7'], 'Z': ['Z_1', 'Z_2', 'Z_3', 'Z_4', 'Z_5', 'Z_6', 'Z_7']}, 'ZT10_16X6x_gg_800nm_m15_roi2_00001_ROIs_classA': {'mean': ['meanFeFv_1', 'meanFeFv_2', 'meanFeFv_3', 'meanFeFv_4', 'meanFeFv_7'], 'X': ['X_1', 'X_2', 'X_3', 'X_4', 'X_7'], 'Y': ['Y_1', 'Y_2', 'Y_3', 'Y_4', 'Y_7'], 'Z': ['Z_1', 'Z_2', 'Z_3', 'Z_4', 'Z_7']}, 'ZT10_16X6x_gg_800nm_m16_roi1_00001_ROIs_classA': {'mean': ['meanFeFv_1', 'meanFeFv_3', 'meanFeFv_6', 'meanFeFv_7', 'meanFeFv_8'], 'X': ['X_1', 'X_3', 'X_6', 'X_7', 'X_8'], 'Y': ['Y_1', 'Y_3', 'Y_6', 'Y_7', 'Y_8'], 'Z': ['Z_1', 'Z_3', 'Z_6', 'Z_7', 'Z_8']}, 'ZT10_16X6x_gg_800nm_m16_roi2_00001_ROIs_classA': {'mean': ['meanFeFv_2', 'meanFeFv_3', 'meanFeFv_6', 'meanFeFv_7', 'meanFeFv_8', 'meanFeFv_9'], 'X': ['X_2', 'X_3', 'X_6', 'X_7', 'X_8', 'X_9'], 'Y': ['Y_2', 'Y_3', 'Y_6', 'Y_7', 'Y_8', 'Y_9'], 'Z': ['Z_2', 'Z_3', 'Z_6', 'Z_7', 'Z_8', 'Z_9']}, 'ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA': {'mean': ['meanFeFv_1', 'meanFeFv_2', 'meanFeFv_3', 'meanFeFv_4'], 'X': ['X_1', 'X_2', 'X_3', 'X_4'], 'Y': ['Y_1', 'Y_2', 'Y_3', 'Y_4'], 'Z': ['Z_1', 'Z_2', 'Z_3', 'Z_4']}, 'ZT10_16X6x_gg_800nm_m5_roi3_00001_ROIs_classA': {'mean': [], 'X': [], 'Y': [], 'Z': []}, 'ZT10_16X6x_gg_800nm_m6_roi1_00001_ROIs_classA': {'mean': ['meanFeFv_1', 'meanFeFv_2', 'meanFeFv_4', 'meanFeFv_5'], 'X': ['X_1', 'X_2', 'X_4', 'X_5'], 'Y': ['Y_1', 'Y_2', 'Y_4', 'Y_5'], 'Z': ['Z_1', 'Z_2', 'Z_4', 'Z_5']}, 'ZT10_16X6x_gg_800nm_m6_roi2_00001_ROIs_classA': {'mean': [], 'X': [], 'Y': [], 'Z': []}, 'ZT10_16X6x_gg_800nm_m6_roi3_00001_ROIs_classA': {'mean': ['meanFeFv_1', 'meanFeFv_2', 'meanFeFv_3', 'meanFeFv_4', 'meanFeFv_5', 'meanFeFv_6', 'meanFeFv_7'], 'X': ['X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7'], 'Y': ['Y_1', 'Y_2', 'Y_3', 'Y_4', 'Y_5', 'Y_6', 'Y_7'], 'Z': ['Z_1', 'Z_2', 'Z_3', 'Z_4', 'Z_5', 'Z_6', 'Z_7']}, 'ZT10_16X6x_gg_800nm_m7_roi1_00001_ROIs_classA': {'mean': ['meanFeFv_1', 'meanFeFv_2', 'meanFeFv_3'], 'X': ['X_1', 'X_2', 'X_3'], 'Y': ['Y_1', 'Y_2', 'Y_3'], 'Z': ['Z_1', 'Z_2', 'Z_3']}, 'ZT10_16X6x_gg_800nm_m9_roi1_00002_ROIs_classA': {'mean': ['meanFeFv_1', 'meanFeFv_2', 'meanFeFv_3', 'meanFeFv_4', 'meanFeFv_6', 'meanFeFv_7'], 'X': ['X_1', 'X_2', 'X_3', 'X_4', 'X_6', 'X_7'], 'Y': ['Y_1', 'Y_2', 'Y_3', 'Y_4', 'Y_6', 'Y_7'], 'Z': ['Z_1', 'Z_2', 'Z_3', 'Z_4', 'Z_6', 'Z_7']}, 'ZT10_16X6x_gg_800nm_m9_roi3_00001_ROIs_classA': {'mean': ['meanFeFv_1', 'meanFeFv_2', 'meanFeFv_3', 'meanFeFv_4', 'meanFeFv_5', 'meanFeFv_6', 'meanFeFv_7', 'meanFeFv_8', 'meanFeFv_9', 'meanFeFv_10', 'meanFeFv_11', 'meanFeFv_13'], 'X': ['X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7', 'X_8', 'X_9', 'X_10', 'X_11', 'X_13'], 'Y': ['Y_1', 'Y_2', 'Y_3', 'Y_4', 'Y_5', 'Y_6', 'Y_7', 'Y_8', 'Y_9', 'Y_10', 'Y_11', 'Y_13'], 'Z': ['Z_1', 'Z_2', 'Z_3', 'Z_4', 'Z_5', 'Z_6', 'Z_7', 'Z_8', 'Z_9', 'Z_10', 'Z_11', 'Z_13']}}\n"
     ]
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "\n",
    "# Example DataFrame with multiple rows (including X, Y, Z coordinates)\n",
    "data = {\n",
    "    'filename': ['ZT10_16X6x_gg_800nm_m10_roi1_00001_ROIs_classA', 'ZT10_16X6x_gg_800nm_m10_roi2_00001_ROIs_classB'],\n",
    "    'capLogical_1': [1, 0],\n",
    "    'capLogical_2': [0, 1],\n",
    "    'venLogical_1': [0, 1],\n",
    "    'venLogical_2': [1, 0],\n",
    "    'artLogical_1': [0, 0],\n",
    "    'artLogical_2': [1, 1],\n",
    "    'meanFeFv_1': [0.338031439, 0.5],\n",
    "    'meanFeFv_2': [0.697814648, 0.6],\n",
    "    'X_1': [10.5, 20.6],\n",
    "    'X_2': [15.2, 21.1],\n",
    "    'Y_1': [5.5, 12.4],\n",
    "    'Y_2': [7.1, 14.3],\n",
    "    'Z_1': [2.2, 5.1],\n",
    "    'Z_2': [3.0, 6.2],\n",
    "}\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# Define logical and mean column prefixes\n",
    "logicalType_cols = ['cap', 'ven', 'art']\n",
    "mean_col_prefix = 'meanFeFv_'\n",
    "logical_col_prefixes = ['capLogical_', 'venLogical_', 'artLogical_']\n",
    "\n",
    "# Get mean, X, Y, Z columns\n",
    "mean_cols = [col for col in df.columns if 'meanFeFv' in col]\n",
    "x_cols = [col for col in df.columns if 'X_' in col]\n",
    "y_cols = [col for col in df.columns if 'Y_' in col]\n",
    "z_cols = [col for col in df.columns if 'Z_' in col]\n",
    "\n",
    "# Create a dictionary to hold the filtered columns for each logical type\n",
    "filtered_cols = {}\n",
    "\n",
    "# Function to get filtered columns based on logical values for each row\n",
    "def get_filtered_cols(row, logical_prefix, mean_prefix, logical_cols):\n",
    "    filtered_mean_cols = []\n",
    "    filtered_x_cols = []\n",
    "    filtered_y_cols = []\n",
    "    filtered_z_cols = []\n",
    "    \n",
    "    for i, logical_col in enumerate(logical_cols):\n",
    "        if row[logical_col] == 1:\n",
    "            mean_col = f\"{mean_prefix}{i+1}\"\n",
    "            if mean_col in mean_cols:\n",
    "                filtered_mean_cols.append(mean_col)\n",
    "            \n",
    "            # Adding X, Y, Z columns\n",
    "            x_col = f\"X_{i+1}\"\n",
    "            y_col = f\"Y_{i+1}\"\n",
    "            z_col = f\"Z_{i+1}\"\n",
    "            \n",
    "            if x_col in x_cols:\n",
    "                filtered_x_cols.append(x_col)\n",
    "            if y_col in y_cols:\n",
    "                filtered_y_cols.append(y_col)\n",
    "            if z_col in z_cols:\n",
    "                filtered_z_cols.append(z_col)\n",
    "    \n",
    "    return filtered_mean_cols, filtered_x_cols, filtered_y_cols, filtered_z_cols\n",
    "\n",
    "# Process each row\n",
    "for index, row in df.iterrows():\n",
    "    # Filter for each vessel type (cap, ven, art) based on row\n",
    "    row_filtered_cols = {}\n",
    "    for logical_prefix in logical_col_prefixes:\n",
    "        vessel_type = logical_prefix.rstrip('Logical_')  # Extract vessel type from prefix\n",
    "        logical_cols = [col for col in df.columns if col.startswith(logical_prefix)]\n",
    "        \n",
    "        mean_cols_filtered, x_cols_filtered, y_cols_filtered, z_cols_filtered = get_filtered_cols(\n",
    "            row, vessel_type, mean_col_prefix, logical_cols\n",
    "        )\n",
    "        \n",
    "        row_filtered_cols[vessel_type] = {\n",
    "            'mean': mean_cols_filtered,\n",
    "            'X': x_cols_filtered,\n",
    "            'Y': y_cols_filtered,\n",
    "            'Z': z_cols_filtered\n",
    "        }\n",
    "    \n",
    "    filename = row['filename']\n",
    "    filtered_cols[filename] = row_filtered_cols\n",
    "\n",
    "# # Example: Extract meanFeFv, X, Y, Z columns for 'cap' for a specific file\n",
    "\n",
    "filenames = list(filtered_cols.keys())\n",
    "filter_keys = list(filtered_cols[filenames[0]].keys()) # ['cap', 'ven', 'art']\n",
    "#print(filter_keys)\n",
    "#print(keys[22])\n",
    "cap_filtered = {}\n",
    "for iFILE in range(len(filenames)): #iFILE = 10\n",
    "    iTYPE = 0\n",
    "    filename = filenames[iFILE] #'ZT10_16X6x_gg_800nm_m10_roi1_00001_ROIs_classA'\n",
    "    vesselKey = filter_keys[iTYPE]\n",
    "    filtered_data = filtered_cols[filename][vesselKey]\n",
    "    cap_filtered[filename] = filtered_data\n",
    "    #cap_filtered[filename] = filtered_cols[filename][vesselKey]\n",
    "    print(f\"Filtered 'cap' columns for file '{filename}':\")\n",
    "#     print(f\"MeanFeFv: {cap_filtered['mean']}\")\n",
    "#     print(f\"X: {cap_filtered['X']}\")\n",
    "#     print(f\"Y: {cap_filtered['Y']}\")\n",
    "#     print(f\"Z: {cap_filtered['Z']}\")\n",
    "\n",
    "    print(vesselKey)\n",
    "    \n",
    "print(cap_filtered)\n",
    "# repeat for \n",
    "# print(ven_filtered)\n",
    "# print(art_filtered) etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc33d2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d14fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(filtered_cols[filename]['cap'])\n",
    "\n",
    "# print(filtered_cols[filename]['ven'])\n",
    "\n",
    "# print(filtered_cols[filename]['art'])\n",
    "\n",
    "# Step 1: Dynamically identify columns that contain the relevant substrings\n",
    "#mean_cols = [col for col in df.columns if 'meanFWHM' in col]\n",
    "# Example of extracting 'meanFWHM' columns for 'cap'\n",
    "# stdev_cols = [col for col in df.columns if 'stdevFWHM' in col]\n",
    "# min_cols = [col for col in df.columns if 'minFWHM' in col]\n",
    "# max_cols = [col for col in df.columns if 'maxFWHM' in col]\n",
    "\n",
    "# Combine all relevant columns\n",
    "#relevant_columns = mean_cols + stdev_cols + min_cols + max_cols\n",
    "\n",
    "# mean FeFev\n",
    "mean_cols_cap = [col for col in filtered_cols[filename]['cap'] if 'meanFeFv' in col]\n",
    "#print(mean_cols_cap)\n",
    "mean_cols_ven = [col for col in filtered_cols[filename]['ven'] if 'meanFeFv' in col]\n",
    "mean_cols_art = [col for col in filtered_cols[filename]['art'] if 'meanFeFv' in col]\n",
    "# X, Y, Z\n",
    "x_cols_cap = [col for col in filtered_cols[filename]['cap'] if 'X' in col]\n",
    "y_cols_cap = [col for col in filtered_cols[filename]['cap'] if 'Y' in col]\n",
    "z_cols_cap = [col for col in filtered_cols[filename]['cap'] if 'Z' in col]\n",
    "x_cols_ven = [col for col in filtered_cols[filename]['ven'] if 'X' in col]\n",
    "y_cols_ven = [col for col in filtered_cols[filename]['ven'] if 'Y' in col]\n",
    "z_cols_ven = [col for col in filtered_cols[filename]['ven'] if 'Z' in col]\n",
    "x_cols_art = [col for col in filtered_cols[filename]['art'] if 'X' in col]\n",
    "y_cols_art = [col for col in filtered_cols[filename]['art'] if 'Y' in col]\n",
    "z_cols_art = [col for col in filtered_cols[filename]['art'] if 'Z' in col]\n",
    "\n",
    "# FWHM\n",
    "# std, min, max\n",
    "\n",
    "# Combine all relevant columns\n",
    "relevant_columns_means = mean_cols_cap + mean_cols_ven + mean_cols_art\n",
    "relevant_columns_x = x_cols_cap + x_cols_ven + x_cols_art\n",
    "relevant_columns_y = y_cols_cap + y_cols_ven + y_cols_art\n",
    "relevant_columns_z = z_cols_cap + z_cols_ven + z_cols_art\n",
    "\n",
    "relevant_columns_ALL = relevant_columns_means + relevant_columns_x + relevant_columns_y + relevant_columns_z\n",
    "print(x_cols_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e0c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Track rows before filtering\n",
    "df_before = df.copy()\n",
    "\n",
    "# Step 3: Drop rows with any of these conditions:\n",
    "# 1. 'roiName' is 'Background'\n",
    "# 2. Row contains NaN in any of the relevant columns\n",
    "# df_clean = df[~((df['roiName'] == 'Background') | df[relevant_columns].isna().any(axis=1))]\n",
    "df_clean = df[~((df['roiName'] == 'Background') & \n",
    "               df['roiName'].duplicated(keep=False))]\n",
    "\n",
    "# Track what was dropped\n",
    "dropped_rows = df_before[~df_before.index.isin(df_clean.index)]\n",
    "print(\"Dropped rows:\")\n",
    "print(dropped_rows[['roiID', 'filename', 'roiName']])\n",
    "\n",
    "# Step 4: For remaining rows, replace NaNs in relevant columns with the row's overall mean\n",
    "for col in relevant_columns:\n",
    "    df_clean[col] = df_clean[col].fillna(df_clean[relevant_columns].mean(axis=1))\n",
    "\n",
    "# print(\"Cleaned up data:\")\n",
    "# print(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668b1a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Perform PCA (after handling NaNs)\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(df_clean[relevant_columns])\n",
    "\n",
    "# Step 6: KMeans clustering\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans_result = kmeans.fit_predict(pca_result)\n",
    "\n",
    "# Step 7: UMAP\n",
    "# umap_model = umap.UMAP(n_neighbors=5)\n",
    "# umap_result = umap_model.fit_transform(df_clean[relevant_columns])\n",
    "\n",
    "# Step 8: Add results back to the clean dataframe\n",
    "df_clean['PCA1'] = pca_result[:, 0]\n",
    "df_clean['PCA2'] = pca_result[:, 1]\n",
    "df_clean['KMeans_cluster'] = kmeans_result\n",
    "# df_clean['UMAP1'] = umap_result[:, 0]\n",
    "# df_clean['UMAP2'] = umap_result[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8c2e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: View results including 'roiID' and 'filename'\n",
    "#print(df_clean[['roiID', 'filename', 'PCA1', 'PCA2', 'KMeans_cluster', 'UMAP1', 'UMAP2']].head())\n",
    "print(df_clean[['roiID', 'roiName', 'filename', 'PCA1', 'PCA2', 'KMeans_cluster', 'group']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f27926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_clusters(df):\n",
    "    # Create a color palette for clusters\n",
    "    n_clusters = df['KMeans_cluster'].nunique()\n",
    "    cluster_colors = sns.color_palette(\"husl\", n_clusters)\n",
    "    markers_list = ['o', 's', 'D', '^', 'v', '<', '>']  # circle, square, diamond, etc.\n",
    "\n",
    "    # Get unique groups\n",
    "    unique_groups = df['group'].unique()\n",
    "\n",
    "    # Create a mapping for group markers and fill styles\n",
    "#     group_markers = {group: 'o' for group in unique_groups}\n",
    "#     group_fill = {group: 'full' if i % 2 == 0 else 'none' for i, group in enumerate(unique_groups)}\n",
    "    group_markers = {group: markers_list[i % len(markers_list)] for i, group in enumerate(unique_groups)}\n",
    "    group_fill = {group: 'full' if i % 2 == 0 else 'none' for i, group in enumerate(unique_groups)}\n",
    "\n",
    "    # Set up the plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot each cluster\n",
    "    for cluster in sorted(df['KMeans_cluster'].unique()):\n",
    "        cluster_data = df[df['KMeans_cluster'] == cluster]\n",
    "        \n",
    "        # Plot each group within the cluster\n",
    "        for group in cluster_data['group'].unique():\n",
    "            group_data = cluster_data[cluster_data['group'] == group]\n",
    "            \n",
    "            plt.scatter(\n",
    "                group_data['PCA1'], \n",
    "                group_data['PCA2'],\n",
    "                c=[cluster_colors[cluster]],\n",
    "                marker=group_markers[group],\n",
    "                facecolors=group_fill[group],\n",
    "                s=80,\n",
    "                edgecolors=cluster_colors[cluster],\n",
    "                linewidth=1.5,\n",
    "                label=f'Cluster {cluster}, Group {group}'\n",
    "            )\n",
    "\n",
    "    plt.xlabel('PCA1')\n",
    "    plt.ylabel('PCA2')\n",
    "    plt.title('Cluster Plot')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Debugging: Print unique clusters and groups\n",
    "    print(\"Unique clusters:\", df['KMeans_cluster'].unique())\n",
    "    print(\"Unique groups:\", df['group'].unique())\n",
    "    print(\"Group markers:\", group_markers)\n",
    "    print(\"Group fill styles:\", group_fill)\n",
    "\n",
    "# Usage:\n",
    "# df = pd.read_csv('your_data.csv')  # Load your data\n",
    "df_copy = df_clean\n",
    "plot_clusters(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65698e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_groups = df_copy['group'].unique()\n",
    "print(unique_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bcb35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['group'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54a4007",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_copy['group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27779ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_copy['KMeans_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3650d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
