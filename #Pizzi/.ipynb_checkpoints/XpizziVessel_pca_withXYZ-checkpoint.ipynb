{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb2ef181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA\n",
      "1     ZT10_16X6x_gg_800nm_m6_roi1_00001_ROIs_classA\n",
      "2     ZT10_16X6x_gg_800nm_m7_roi1_00001_ROIs_classA\n",
      "3     ZT10_16X6x_gg_800nm_m9_roi1_00002_ROIs_classA\n",
      "4    ZT10_16X6x_gg_800nm_m10_roi1_00001_ROIs_classA\n",
      "5    ZT10_16X6x_gg_800nm_m11_roi1_00001_ROIs_classA\n",
      "6    ZT10_16X6x_gg_800nm_m12_roi1_00001_ROIs_classA\n",
      "7    ZT10_16X6x_gg_800nm_m13_roi1_00002_ROIs_classA\n",
      "8    ZT10_16X6x_gg_800nm_m15_roi1_00001_ROIs_classA\n",
      "9    ZT10_16X6x_gg_800nm_m16_roi1_00001_ROIs_classA\n",
      "Name: filename, dtype: object\n",
      "0    A\n",
      "1    A\n",
      "2    B\n",
      "3    A\n",
      "4    A\n",
      "5    A\n",
      "6    A\n",
      "7    B\n",
      "8    B\n",
      "9    B\n",
      "Name: group, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "pathname = '/Users/jcoleman/Documents/--LARGE DATA--/#Pizzi/TBI-sham leak analysis/scripts/matlab-copy/September 2024/'\n",
    "filename = 'analysisData_091724.csv'\n",
    "df = pd.read_csv(pathname+filename)\n",
    "\n",
    "print(df['filename'])\n",
    "print(df['group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53989af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTable = pd.read_table(pathname+filename)\n",
    "\n",
    "# print(dfTable.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c2a5404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation complete. Output files have been generated.\n",
      "Be sure to delete all rows with empty cells/nans before PCA.\n"
     ]
    }
   ],
   "source": [
    "# Transfrom CSV from allData (MATLAB output)\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Convention and column order: It's generally better to keep the 'rowID' as the first column across all output files for consistency.\n",
    "This makes it easier to identify and work with the data, especially when doing analyses or merging datasets later.\n",
    "Data format: The format we've created is indeed considered \"long\" or \"tidy\" format.\n",
    "\n",
    "In tidy data:\n",
    "Each variable forms a column\n",
    "Each observation forms a row\n",
    "Each type of observational unit forms a table\n",
    "\n",
    "This format is preferred for many types of analyses and is especially useful for tools like ggplot in R\n",
    "or seaborn in Python.\n",
    "\"\"\"\n",
    "\n",
    "# Read the input CSV file\n",
    "# input_file = 'sampleData2_input.csv'\n",
    "# df = pd.read_csv(input_file)\n",
    "\n",
    "# Assuming maximum 40 measurements per row per metric/set of values\n",
    "# Set the max number of 'rois' (ie data values per metric per observation-subject in the dataset)\n",
    "max_roi_num = 40\n",
    "\n",
    "headers_to_extract = ['meanFWHM', 'stdevFWHM', 'minFWHM', 'maxFWHM', 'meanFeFv', 'stdevFeFv', 'minFeFv', 'maxFeFv', 'X', 'Y', 'Z']\n",
    "# TESTheaders_to_extract = ['meanFWHM', 'stdevFWHM', 'minFWHM', 'maxFWHM']\n",
    "logicals_to_extract = [\n",
    "    'capLogical',\n",
    "    'venLogical',\n",
    "    'artLogical',\n",
    "    'midLogical',\n",
    "    'preLogical',\n",
    "    'pstLogical',\n",
    "    'midCapLogical',\n",
    "    'preCapLogical',\n",
    "    'pstCapLogical',\n",
    "    'midVenLogical',\n",
    "    'preVenLogical',\n",
    "    'pstVenLogical',\n",
    "    'midArtLogical',\n",
    "    'preArtLogical',\n",
    "    'pstArtLogical',\n",
    "]\n",
    "# logicals_to_extract = ['capLogical', 'venLogical', 'artLogical']\n",
    "# logicals_to_extract = ['capLogical', 'venLogical']\n",
    "\n",
    "# Function to create the rowID\n",
    "def create_row_id(row, index):\n",
    "    return f\"{row['filename']}_{index:02d}\"\n",
    "\n",
    "# Function to extract columns and create new rows\n",
    "def extract_columns(row):\n",
    "    new_rows = []\n",
    "    for i in range(1, max_roi_num): # Set maximum measurements per row per metric per set of values (ie rois analyzed per subject)\n",
    "        new_row = {'rowID': create_row_id(row, i)}\n",
    "        for header in headers_to_extract:\n",
    "            new_row[header] = row.get(f\"{header}_{i}\", np.nan)\n",
    "        for logical in logicals_to_extract:\n",
    "            new_row[logical] = row.get(f\"{logical}_{i}\", np.nan)\n",
    "        new_row['group'] = row['group']\n",
    "        new_rows.append(new_row)\n",
    "    return new_rows\n",
    "\n",
    "# Create the new dataframe\n",
    "new_rows = [row for rows in df.apply(extract_columns, axis=1) for row in rows]\n",
    "df_output = pd.DataFrame(new_rows)\n",
    "\n",
    "# Ensure 'rowID' is the first column\n",
    "column_order = ['rowID'] + [col for col in df_output.columns if col != 'rowID']\n",
    "df_output = df_output[column_order]\n",
    "\n",
    "# Create output1a (with all rows, including those with NaN values)\n",
    "df_output1a = df_output.copy()\n",
    "df_output1a.to_csv('Data1_output1a_transii.csv', index=False)\n",
    "\n",
    "# Create output1b (without rows that have all NaN values in headers_to_extract)\n",
    "df_output1b = df_output[df_output[headers_to_extract].notna().any(axis=1)]\n",
    "df_output1b.to_csv('Data1_output1b_transii.csv', index=False)\n",
    "\n",
    "# Create output1c (without logicals and group, and without rows that have all NaN values in headers_to_extract)\n",
    "df_output1c = df_output[['rowID'] + headers_to_extract]\n",
    "df_output1c = df_output1c[df_output1c[headers_to_extract].notna().any(axis=1)]\n",
    "df_output1c.to_csv('Data1_output1c_transii.csv', index=False)\n",
    "\n",
    "print(\"Transformation complete. Output files have been generated.\")\n",
    "print(\"Be sure to delete all rows with empty cells/nans before PCA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "022d06eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              rowID  meanFWHM  stdevFWHM  \\\n",
      "0  ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA_01  3.740378   0.120027   \n",
      "1  ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA_02  4.100067   0.120158   \n",
      "2  ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA_03  6.326261   0.091814   \n",
      "3  ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA_04  6.066305   0.070735   \n",
      "4  ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA_05       NaN        NaN   \n",
      "\n",
      "    minFWHM   maxFWHM  meanFeFv  stdevFeFv   minFeFv   maxFeFv      X      Y  \\\n",
      "0  3.542297  3.907355  0.301351   0.088444  0.164055  0.406216   30.0  366.5   \n",
      "1  3.922870  4.245508  0.718676   0.103000  0.559359  0.933077  213.0  242.0   \n",
      "2  6.202881  6.441604  0.083048   0.026864  0.049834  0.148631  436.0  193.5   \n",
      "3  5.974274  6.145408  0.849531   0.084406  0.713789  0.964376  278.0  245.0   \n",
      "4       NaN       NaN       NaN        NaN       NaN       NaN  326.0  252.0   \n",
      "\n",
      "      Z  \n",
      "0  10.0  \n",
      "1  20.0  \n",
      "2  25.0  \n",
      "3  55.0  \n",
      "4  40.0  \n",
      "(390, 28)\n",
      "(212, 28)\n",
      "(212, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df_output1c.head())\n",
    "\n",
    "print(df_output1a.shape)\n",
    "print(df_output1b.shape)\n",
    "print(df_output1c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7c71cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               rowID  meanFWHM  stdevFWHM  \\\n",
      "0   ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA_01  3.740378   0.120027   \n",
      "1   ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA_02  4.100067   0.120158   \n",
      "2   ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA_03  6.326261   0.091814   \n",
      "3   ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA_04  6.066305   0.070735   \n",
      "39  ZT10_16X6x_gg_800nm_m6_roi1_00001_ROIs_classA_01  5.886713   0.134211   \n",
      "\n",
      "     minFWHM   maxFWHM  meanFeFv  stdevFeFv   minFeFv   maxFeFv      X  ...  \\\n",
      "0   3.542297  3.907355  0.301351   0.088444  0.164055  0.406216   30.0  ...   \n",
      "1   3.922870  4.245508  0.718676   0.103000  0.559359  0.933077  213.0  ...   \n",
      "2   6.202881  6.441604  0.083048   0.026864  0.049834  0.148631  436.0  ...   \n",
      "3   5.974274  6.145408  0.849531   0.084406  0.713789  0.964376  278.0  ...   \n",
      "39  5.693535  6.101866  0.222588   0.057162  0.110756  0.307333  404.0  ...   \n",
      "\n",
      "    midCapLogical  preCapLogical  pstCapLogical  midVenLogical  preVenLogical  \\\n",
      "0             1.0            0.0            0.0            0.0            0.0   \n",
      "1             0.0            1.0            0.0            0.0            0.0   \n",
      "2             1.0            0.0            0.0            0.0            0.0   \n",
      "3             0.0            1.0            0.0            0.0            0.0   \n",
      "39            1.0            0.0            0.0            0.0            0.0   \n",
      "\n",
      "    pstVenLogical  midArtLogical  preArtLogical  pstArtLogical  group  \n",
      "0             0.0            0.0            0.0            0.0      A  \n",
      "1             0.0            0.0            0.0            0.0      A  \n",
      "2             0.0            0.0            0.0            0.0      A  \n",
      "3             0.0            0.0            0.0            0.0      A  \n",
      "39            0.0            0.0            0.0            0.0      A  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "(190, 28)\n"
     ]
    }
   ],
   "source": [
    "df_pca_withIDs = df_output1b.dropna(how='any')\n",
    "df_pca_withIDs.to_csv('df_pca_withIDs.csv', index=False)\n",
    "print(df_pca_withIDs.head())\n",
    "print(df_pca_withIDs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f44c4338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    meanFWHM  stdevFWHM   minFWHM   maxFWHM  meanFeFv  stdevFeFv   minFeFv  \\\n",
      "0   3.740378   0.120027  3.542297  3.907355  0.301351   0.088444  0.164055   \n",
      "1   4.100067   0.120158  3.922870  4.245508  0.718676   0.103000  0.559359   \n",
      "2   6.326261   0.091814  6.202881  6.441604  0.083048   0.026864  0.049834   \n",
      "3   6.066305   0.070735  5.974274  6.145408  0.849531   0.084406  0.713789   \n",
      "39  5.886713   0.134211  5.693535  6.101866  0.222588   0.057162  0.110756   \n",
      "\n",
      "     maxFeFv      X      Y     Z  \n",
      "0   0.406216   30.0  366.5  10.0  \n",
      "1   0.933077  213.0  242.0  20.0  \n",
      "2   0.148631  436.0  193.5  25.0  \n",
      "3   0.964376  278.0  245.0  55.0  \n",
      "39  0.307333  404.0  267.5  15.0  \n",
      "(190, 12)\n",
      "object\n",
      "(190, 11)\n"
     ]
    }
   ],
   "source": [
    "df_for_pca_temp = df_output1c.dropna(how='any')\n",
    "# df_for_pca_clean = df_for_pca_temp[df_for_pca_temp['rowID'] != 'row_to_ignore']\n",
    "df_for_pca_clean  = df_for_pca_temp.drop('rowID', axis=1)\n",
    "\n",
    "df_for_pca_clean.to_csv('df_for_pca_clean.csv', index=False)\n",
    "print(df_for_pca_clean.head())\n",
    "print(df_for_pca_temp.shape)\n",
    "print(df_for_pca_temp['rowID'].dtype)\n",
    "print(df_for_pca_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc05526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA_01     1\n",
      "ZT10_16X6x_gg_800nm_m13_roi1_00002_ROIs_classA_07    1\n",
      "ZT10_16X6x_gg_800nm_m12_roi1_00001_ROIs_classA_35    1\n",
      "ZT10_16X6x_gg_800nm_m12_roi1_00001_ROIs_classA_36    1\n",
      "ZT10_16X6x_gg_800nm_m12_roi1_00001_ROIs_classA_37    1\n",
      "                                                    ..\n",
      "ZT10_16X6x_gg_800nm_m11_roi1_00001_ROIs_classA_08    1\n",
      "ZT10_16X6x_gg_800nm_m11_roi1_00001_ROIs_classA_09    1\n",
      "ZT10_16X6x_gg_800nm_m11_roi1_00001_ROIs_classA_10    1\n",
      "ZT10_16X6x_gg_800nm_m11_roi1_00001_ROIs_classA_11    1\n",
      "ZT10_16X6x_gg_800nm_m16_roi1_00001_ROIs_classA_18    1\n",
      "Name: rowID, Length: 190, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print(df_for_pca_temp['rowID'].head())  # Show first few values\n",
    "# print(df_for_pca_temp['rowID'].unique())  # Show unique values\n",
    "print(df_for_pca_temp['rowID'].value_counts())  # Show value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5f0dbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PCA Analysis ---\n",
      "    meanFWHM  stdevFWHM   minFWHM   maxFWHM  meanFeFv  stdevFeFv   minFeFv  \\\n",
      "0  -0.753129  -0.264182 -0.734643 -0.770704 -0.957662  -0.428220 -1.055814   \n",
      "1  -0.552381  -0.263166 -0.520402 -0.585311 -0.241254  -0.335022 -0.180405   \n",
      "2   0.690091  -0.481656  0.763115  0.618701 -1.332417  -0.822510 -1.308759   \n",
      "3   0.545006  -0.644145  0.634423  0.456311 -0.016618  -0.454078  0.161582   \n",
      "39  0.444773  -0.154842  0.476382  0.432439 -1.092873  -0.628519 -1.173847   \n",
      "\n",
      "     maxFeFv         X         Y         Z  \n",
      "0  -0.929415 -1.885572  0.857047 -0.857653  \n",
      "1  -0.250892 -0.423227 -0.125455 -0.550771  \n",
      "2  -1.261148  1.358758 -0.508198 -0.397331  \n",
      "3  -0.210584  0.096186 -0.101781  0.523314  \n",
      "39 -1.056762  1.103047  0.075780 -0.704212  \n",
      "(190, 11)\n"
     ]
    }
   ],
   "source": [
    "# Now, let's separate the PCA analysis\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(\"\\n--- PCA Analysis ---\")\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(df_for_pca_clean), \n",
    "    columns=df_for_pca_clean.columns, \n",
    "    index=df_for_pca_clean.index\n",
    ")\n",
    "\n",
    "print(df_scaled.head())\n",
    "print(df_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01344902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PCA Results:\n",
      "         PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
      "0  -0.810099 -1.903101 -1.096663  1.098158 -1.176242  1.255756  0.472275   \n",
      "1   0.013084 -1.176117 -0.480430  0.332637 -0.149351  0.005491 -0.046360   \n",
      "2  -2.720859 -0.233999  0.714641 -0.165460 -0.049003 -1.300054 -0.033786   \n",
      "3  -0.770911  0.628583 -0.407216 -0.719726  0.454261 -0.094246  0.059339   \n",
      "39 -2.112532 -0.317172  0.642505  0.049830 -0.674384 -0.984919 -0.165679   \n",
      "\n",
      "         PC8       PC9      PC10      PC11  \n",
      "0  -0.066666 -0.021643 -0.008302  0.006035  \n",
      "1  -0.009250  0.045032  0.004035 -0.020908  \n",
      "2  -0.032113 -0.004266 -0.007326 -0.014480  \n",
      "3   0.004291 -0.026413 -0.002708 -0.017918  \n",
      "39 -0.082432 -0.002754 -0.018187  0.007628  \n"
     ]
    }
   ],
   "source": [
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(df_scaled)\n",
    "\n",
    "# Create a DataFrame with PCA results\n",
    "pca_df = pd.DataFrame(\n",
    "    data=pca_result,\n",
    "    columns=[f'PC{i+1}' for i in range(pca_result.shape[1])],\n",
    "    index=df_for_pca_clean.index\n",
    ")\n",
    "\n",
    "print(\"\\nPCA Results:\")\n",
    "print(pca_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36856809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Explained Variance Ratio:\n",
      "PC1: 0.3195\n",
      "PC2: 0.2681\n",
      "PC3: 0.1064\n",
      "PC4: 0.0974\n",
      "PC5: 0.0888\n",
      "PC6: 0.0762\n",
      "PC7: 0.0416\n",
      "PC8: 0.0013\n",
      "PC9: 0.0005\n",
      "PC10: 0.0001\n",
      "PC11: 0.0000\n",
      "\n",
      "Cumulative Explained Variance Ratio:\n",
      "PC1 to PC1: 0.3195\n",
      "PC1 to PC2: 0.5876\n",
      "PC1 to PC3: 0.6939\n",
      "PC1 to PC4: 0.7914\n",
      "PC1 to PC5: 0.8802\n",
      "PC1 to PC6: 0.9564\n",
      "PC1 to PC7: 0.9980\n",
      "PC1 to PC8: 0.9994\n",
      "PC1 to PC9: 0.9999\n",
      "PC1 to PC10: 1.0000\n",
      "PC1 to PC11: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "for i, ratio in enumerate(explained_variance_ratio):\n",
    "    print(f\"PC{i+1}: {ratio:.4f}\")\n",
    "\n",
    "# Cumulative explained variance\n",
    "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "print(\"\\nCumulative Explained Variance Ratio:\")\n",
    "for i, ratio in enumerate(cumulative_variance_ratio):\n",
    "    print(f\"PC1 to PC{i+1}: {ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb4b71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
