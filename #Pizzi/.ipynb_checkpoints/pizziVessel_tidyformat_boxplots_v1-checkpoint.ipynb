{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2ef181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA\n",
      "1     ZT10_16X6x_gg_800nm_m6_roi1_00001_ROIs_classA\n",
      "2     ZT10_16X6x_gg_800nm_m7_roi1_00001_ROIs_classA\n",
      "3     ZT10_16X6x_gg_800nm_m9_roi1_00002_ROIs_classA\n",
      "4    ZT10_16X6x_gg_800nm_m10_roi1_00001_ROIs_classA\n",
      "5    ZT10_16X6x_gg_800nm_m11_roi1_00001_ROIs_classA\n",
      "6    ZT10_16X6x_gg_800nm_m12_roi1_00001_ROIs_classA\n",
      "7    ZT10_16X6x_gg_800nm_m13_roi1_00002_ROIs_classA\n",
      "8    ZT10_16X6x_gg_800nm_m15_roi1_00001_ROIs_classA\n",
      "9    ZT10_16X6x_gg_800nm_m16_roi1_00001_ROIs_classA\n",
      "Name: filename, dtype: object\n",
      "0    A\n",
      "1    A\n",
      "2    B\n",
      "3    A\n",
      "4    A\n",
      "5    A\n",
      "6    A\n",
      "7    B\n",
      "8    B\n",
      "9    B\n",
      "Name: group, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "pathname = '/Users/jcoleman/Documents/--LARGE DATA--/#Pizzi/TBI-sham leak analysis/scripts/matlab-copy/September 2024/'\n",
    "filename = 'analysisData_091724.csv'\n",
    "df = pd.read_csv(pathname+filename)\n",
    "\n",
    "print(df['filename'])\n",
    "print(df['group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c53989af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTable = pd.read_table(pathname+filename)\n",
    "\n",
    "# print(dfTable.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c2a5404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation complete. Output files have been generated.\n",
      "Be sure to delete all rows with empty cells/nans before PCA.\n"
     ]
    }
   ],
   "source": [
    "# Transfrom CSV from allData (MATLAB output)\n",
    "# import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Convention and column order: It's generally better to keep the 'rowID' as the first column across all output files for consistency.\n",
    "This makes it easier to identify and work with the data, especially when doing analyses or merging datasets later.\n",
    "Data format: The format we've created is indeed considered \"long\" or \"tidy\" format.\n",
    "\n",
    "In tidy data:\n",
    "Each variable forms a column\n",
    "Each observation forms a row\n",
    "Each type of observational unit forms a table\n",
    "\n",
    "This format is preferred for many types of analyses and is especially useful for tools like ggplot in R\n",
    "or seaborn in Python.\n",
    "\"\"\"\n",
    "\n",
    "# Read the input CSV file\n",
    "# input_file = 'sampleData2_input.csv'\n",
    "# df = pd.read_csv(input_file)\n",
    "\n",
    "# Assuming maximum 40 measurements per row per metric/set of values\n",
    "# Set the max number of 'rois' (ie data values per metric per observation-subject in the dataset)\n",
    "max_roi_num = 40\n",
    "\n",
    "headers_to_extract = ['meanFWHM', 'stdevFWHM', 'minFWHM', 'maxFWHM', 'meanFeFv', 'stdevFeFv', 'minFeFv', 'maxFeFv']\n",
    "# TESTheaders_to_extract = ['meanFWHM', 'stdevFWHM', 'minFWHM', 'maxFWHM']\n",
    "logicals_to_extract = [\n",
    "    'capLogical',\n",
    "    'venLogical',\n",
    "    'artLogical',\n",
    "    'midLogical',\n",
    "    'preLogical',\n",
    "    'pstLogical',\n",
    "    'midCapLogical',\n",
    "    'preCapLogical',\n",
    "    'pstCapLogical',\n",
    "    'midVenLogical',\n",
    "    'preVenLogical',\n",
    "    'pstVenLogical',\n",
    "    'midArtLogical',\n",
    "    'preArtLogical',\n",
    "    'pstArtLogical',\n",
    "]\n",
    "# logicals_to_extract = ['capLogical', 'venLogical', 'artLogical']\n",
    "# logicals_to_extract = ['capLogical', 'venLogical']\n",
    "\n",
    "# Function to create the rowID\n",
    "def create_row_id(row, index):\n",
    "    return f\"{row['filename']}_{index:02d}\"\n",
    "\n",
    "# Function to extract columns and create new rows\n",
    "def extract_columns(row):\n",
    "    new_rows = []\n",
    "    for i in range(1, max_roi_num): # Set maximum measurements per row per metric per set of values (ie rois analyzed per subject)\n",
    "        new_row = {'rowID': create_row_id(row, i)}\n",
    "        for header in headers_to_extract:\n",
    "            new_row[header] = row.get(f\"{header}_{i}\", np.nan)\n",
    "        for logical in logicals_to_extract:\n",
    "            new_row[logical] = row.get(f\"{logical}_{i}\", np.nan)\n",
    "        new_row['group'] = row['group']\n",
    "        new_rows.append(new_row)\n",
    "    return new_rows\n",
    "\n",
    "# Create the new dataframe\n",
    "new_rows = [row for rows in df.apply(extract_columns, axis=1) for row in rows]\n",
    "df_output = pd.DataFrame(new_rows)\n",
    "\n",
    "# Ensure 'rowID' is the first column\n",
    "column_order = ['rowID'] + [col for col in df_output.columns if col != 'rowID']\n",
    "df_output = df_output[column_order]\n",
    "\n",
    "# Create output1a (with all rows, including those with NaN values)\n",
    "df_output1a = df_output.copy()\n",
    "df_output1a.to_csv('Data1_output1a_transii.csv', index=False)\n",
    "\n",
    "# Create output1b (without rows that have all NaN values in headers_to_extract)\n",
    "df_output1b = df_output[df_output[headers_to_extract].notna().any(axis=1)]\n",
    "df_output1b.to_csv('Data1_output1b_transii.csv', index=False)\n",
    "\n",
    "# Create output1c (without logicals and group, and without rows that have all NaN values in headers_to_extract)\n",
    "df_output1c = df_output[['rowID'] + headers_to_extract]\n",
    "df_output1c = df_output1c[df_output1c[headers_to_extract].notna().any(axis=1)]\n",
    "df_output1c.to_csv('Data1_output1c_transii.csv', index=False)\n",
    "\n",
    "print(\"Transformation complete. Output files have been generated.\")\n",
    "print(\"Be sure to delete all rows with empty cells/nans before PCA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "022d06eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               rowID  meanFWHM  stdevFWHM  \\\n",
      "0   ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA_01  3.740378   0.120027   \n",
      "1   ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA_02  4.100067   0.120158   \n",
      "2   ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA_03  6.326261   0.091814   \n",
      "3   ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA_04  6.066305   0.070735   \n",
      "39  ZT10_16X6x_gg_800nm_m6_roi1_00001_ROIs_classA_01  5.886713   0.134211   \n",
      "\n",
      "     minFWHM   maxFWHM  meanFeFv  stdevFeFv   minFeFv   maxFeFv  \n",
      "0   3.542297  3.907355  0.301351   0.088444  0.164055  0.406216  \n",
      "1   3.922870  4.245508  0.718676   0.103000  0.559359  0.933077  \n",
      "2   6.202881  6.441604  0.083048   0.026864  0.049834  0.148631  \n",
      "3   5.974274  6.145408  0.849531   0.084406  0.713789  0.964376  \n",
      "39  5.693535  6.101866  0.222588   0.057162  0.110756  0.307333  \n",
      "(390, 25)\n",
      "(192, 25)\n",
      "(192, 9)\n"
     ]
    }
   ],
   "source": [
    "print(df_output1c.head())\n",
    "\n",
    "print(df_output1a.shape)\n",
    "print(df_output1b.shape)\n",
    "print(df_output1c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c71cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               rowID  meanFWHM  stdevFWHM  \\\n",
      "0   ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA_01  3.740378   0.120027   \n",
      "1   ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA_02  4.100067   0.120158   \n",
      "2   ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA_03  6.326261   0.091814   \n",
      "3   ZT10_16X6x_gg_800nm_m5_roi2_00003_ROIs_classA_04  6.066305   0.070735   \n",
      "39  ZT10_16X6x_gg_800nm_m6_roi1_00001_ROIs_classA_01  5.886713   0.134211   \n",
      "\n",
      "     minFWHM   maxFWHM  meanFeFv  stdevFeFv   minFeFv   maxFeFv  capLogical  \\\n",
      "0   3.542297  3.907355  0.301351   0.088444  0.164055  0.406216         1.0   \n",
      "1   3.922870  4.245508  0.718676   0.103000  0.559359  0.933077         1.0   \n",
      "2   6.202881  6.441604  0.083048   0.026864  0.049834  0.148631         1.0   \n",
      "3   5.974274  6.145408  0.849531   0.084406  0.713789  0.964376         1.0   \n",
      "39  5.693535  6.101866  0.222588   0.057162  0.110756  0.307333         1.0   \n",
      "\n",
      "    ...  midCapLogical  preCapLogical  pstCapLogical  midVenLogical  \\\n",
      "0   ...            1.0            0.0            0.0            0.0   \n",
      "1   ...            0.0            1.0            0.0            0.0   \n",
      "2   ...            1.0            0.0            0.0            0.0   \n",
      "3   ...            0.0            1.0            0.0            0.0   \n",
      "39  ...            1.0            0.0            0.0            0.0   \n",
      "\n",
      "    preVenLogical  pstVenLogical  midArtLogical  preArtLogical  pstArtLogical  \\\n",
      "0             0.0            0.0            0.0            0.0            0.0   \n",
      "1             0.0            0.0            0.0            0.0            0.0   \n",
      "2             0.0            0.0            0.0            0.0            0.0   \n",
      "3             0.0            0.0            0.0            0.0            0.0   \n",
      "39            0.0            0.0            0.0            0.0            0.0   \n",
      "\n",
      "    group  \n",
      "0       A  \n",
      "1       A  \n",
      "2       A  \n",
      "3       A  \n",
      "39      A  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "(190, 25)\n"
     ]
    }
   ],
   "source": [
    "df_pca_withIDs = df_output1b.dropna(how='any')\n",
    "df_pca_withIDs.to_csv('df_pca_withIDs.csv', index=False)\n",
    "print(df_pca_withIDs.head())\n",
    "print(df_pca_withIDs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4570bc60",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_pca_withIDs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bh/28kxn85n7dzd4095hz5d9rpnf092bp/T/ipykernel_44008/4087557425.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# data = pd.read_csv(\"sampleData3_tidyinput.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_pca_withIDs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Set up the plot style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_pca_withIDs' is not defined"
     ]
    }
   ],
   "source": [
    "# Boxplot code using 'df_pca_withIDs'\n",
    "\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# # Read the CSV file\n",
    "# data = pd.read_csv(\"sampleData3_tidyinput.csv\")\n",
    "\n",
    "data = df_pca_withIDs\n",
    "\n",
    "# Set up the plot style\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ec920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create box plots\n",
    "def create_boxplot(data, x, y, hue, title, ax):\n",
    "    sns.boxplot(x=x, y=y, hue=hue, data=data, ax=ax)\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel(y)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Create a 2x2 subplot\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle('Vessel Characteristics by Group and Type', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot for meanFWHM by group\n",
    "create_boxplot(data, 'group', 'meanFWHM', 'group', 'Mean FWHM by Group', axs[0, 0])\n",
    "\n",
    "# Plot for meanFWHM by vessel type\n",
    "vessel_data = pd.melt(data, id_vars=['meanFWHM'], \n",
    "                      value_vars=['capLogical', 'venLogical', 'artLogical'],\n",
    "                      var_name='vessel_type', value_name='value')\n",
    "vessel_data = vessel_data[vessel_data['value'] == 1]\n",
    "vessel_data['vessel_type'] = vessel_data['vessel_type'].str.replace('Logical', '')\n",
    "create_boxplot(vessel_data, 'vessel_type', 'meanFWHM', 'vessel_type', 'Mean FWHM by Vessel Type', axs[0, 1])\n",
    "\n",
    "# Plot for meanFeFv by group\n",
    "create_boxplot(data, 'group', 'meanFeFv', 'group', 'Mean FeFv by Group', axs[1, 0])\n",
    "\n",
    "# Plot for meanFeFv by vessel type\n",
    "vessel_data = pd.melt(data, id_vars=['meanFeFv'], \n",
    "                      value_vars=['capLogical', 'venLogical', 'artLogical'],\n",
    "                      var_name='vessel_type', value_name='value')\n",
    "vessel_data = vessel_data[vessel_data['value'] == 1]\n",
    "vessel_data['vessel_type'] = vessel_data['vessel_type'].str.replace('Logical', '')\n",
    "create_boxplot(vessel_data, 'vessel_type', 'meanFeFv', 'vessel_type', 'Mean FeFv by Vessel Type', axs[1, 1])\n",
    "\n",
    "# Adjust layout and save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('combined_boxplots_python.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Additional plot for all variables by group\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.boxplot(x='variable', y='value', hue='group', data=pd.melt(data, id_vars=['group'], value_vars=['meanFWHM', 'meanFeFv']), ax=ax)\n",
    "ax.set_title('FWHM and FeFv by Group', fontweight='bold')\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Value')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('all_variables_boxplot_python.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06efa109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc05526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(df_for_pca_temp['rowID'].head())  # Show first few values\n",
    "# # print(df_for_pca_temp['rowID'].unique())  # Show unique values\n",
    "# print(df_for_pca_temp['rowID'].value_counts())  # Show value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5f0dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now, let's separate the PCA analysis\n",
    "# import numpy as np\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# print(\"\\n--- PCA Analysis ---\")\n",
    "\n",
    "# # Scale the data\n",
    "# scaler = StandardScaler()\n",
    "# df_scaled = pd.DataFrame(\n",
    "#     scaler.fit_transform(df_for_pca_clean), \n",
    "#     columns=df_for_pca_clean.columns, \n",
    "#     index=df_for_pca_clean.index\n",
    "# )\n",
    "\n",
    "# print(df_scaled.head())\n",
    "# print(df_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01344902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform PCA\n",
    "# pca = PCA()\n",
    "# pca_result = pca.fit_transform(df_scaled)\n",
    "\n",
    "# # Create a DataFrame with PCA results\n",
    "# pca_df = pd.DataFrame(\n",
    "#     data=pca_result,\n",
    "#     columns=[f'PC{i+1}' for i in range(pca_result.shape[1])],\n",
    "#     index=df_for_pca_clean.index\n",
    "# )\n",
    "\n",
    "# print(\"\\nPCA Results:\")\n",
    "# print(pca_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36856809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate and print explained variance ratio\n",
    "# explained_variance_ratio = pca.explained_variance_ratio_\n",
    "# print(\"\\nExplained Variance Ratio:\")\n",
    "# for i, ratio in enumerate(explained_variance_ratio):\n",
    "#     print(f\"PC{i+1}: {ratio:.4f}\")\n",
    "\n",
    "# # Cumulative explained variance\n",
    "# cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "# print(\"\\nCumulative Explained Variance Ratio:\")\n",
    "# for i, ratio in enumerate(cumulative_variance_ratio):\n",
    "#     print(f\"PC1 to PC{i+1}: {ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb4b71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
